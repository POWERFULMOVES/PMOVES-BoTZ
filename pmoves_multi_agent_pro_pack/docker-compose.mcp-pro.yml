version: "3.9"

x-env-files: &env_files
  - ./env.shared
  - ./.env
  - ./.env.local

services:
  tailscale:
    image: tailscale/tailscale:stable
    hostname: pmoves-pro
    environment:
      - TS_AUTHKEY=${TS_AUTHKEY}
      - TS_STATE_DIR=/var/lib/tailscale
      - TS_USERSPACE=false
      - TS_ACCEPT_DNS=true
    cap_add: [ "NET_ADMIN", "NET_RAW" ]
    volumes:
      - ./ts-state:/var/lib/tailscale
    network_mode: host
    restart: unless-stopped
    command: >
      sh -lc "
      tailscaled --state=/var/lib/tailscale/tailscaled.state &
      sleep 2 &&
      tailscale up --authkey=${TS_AUTHKEY} --reset --accept-routes=true --ssh=true &&
      tailscale serve https / http://127.0.0.1:2091 &&
      tail -f /dev/null
      "

  mcp-gateway:
    image: alpine:3.20
    working_dir: /app
    entrypoint: ["/bin/sh","-lc"]
    command: >
      "
      apk add --no-cache bash curl python3 py3-pip pipx docker-cli-plugins &&
      pipx ensurepath &&
      docker mcp gateway run --port 2091 --transport streaming --catalog /app/mcp_catalog_multi.yaml
      "
    env_file: *env_files
    volumes:
      - ./mcp_catalog_multi.yaml:/app/mcp_catalog_multi.yaml:ro
    network_mode: host
    restart: unless-stopped

  # Docling MCP as standalone HTTP server (portable)
  docling-mcp:
    image: python:3.11-slim
    working_dir: /srv
    environment:
      DOC_CACHE_DIR: /data/cache
    volumes:
      - ./data/docling:/data
    command: >
      sh -lc "
      pip install --no-cache-dir docling-mcp &&
      docling-mcp-server --transport streamable-http --host 0.0.0.0 --port 3020
      "
    ports: [ "3020:3020" ]
    restart: unless-stopped

  # E2B sandbox runner shim (HTTP) — uses E2B Python SDK
  e2b-runner:
    build: ./e2b_shim
    environment:
      E2B_API_KEY: ${E2B_API_KEY}
      SANDBOX_TTL_SEC: ${SANDBOX_TTL_SEC:-1800}
    ports: [ "7071:7071" ]
    restart: unless-stopped

  # Vision-Language sentinel (guidance/monitoring) — pluggable provider
  vl-sentinel:
    build: ./vl_sentinel
    environment:
      VL_PROVIDER: ${VL_PROVIDER:-ollama}
      VL_MODEL: ${VL_MODEL:-qwen2.5-vl:14b}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
    ports: [ "7072:7072" ]
    restart: unless-stopped

# Optional: run Postman MCP locally (STDIO) in Node — prefer hosted HTTP.
#  postman-mcp-local:
#    image: node:20-alpine
#    working_dir: /srv
#    command: ["npx","@postman/postman-mcp-server@latest","--full"]
#    environment:
#      POSTMAN_API_KEY: ${POSTMAN_API_KEY}
#    network_mode: host
#    restart: unless-stopped